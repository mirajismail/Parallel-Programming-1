# Q4
Change directory into omplaplace\_serial\_1 and run:

```
source teachsetup
make clean
make
```

I ran into some problems regarding line granularity of gmon ( `gmon -l <binary>`) so I used function granularity and found the following:

```
Flat profile:

Each sample counts as 0.01 seconds.

  %   cumulative   self               self      total
 time   seconds   seconds   calls    us/call   us/call   name
51.15     21.96    21.96    69620     315.36    315.36   get_max_diff(ra::rarray<double, 2> const&, ra::rarray<double, 2> const&)
48.31     42.69    20.74    69623     297.82    297.82   apply_average(ra::rarray<double, 2>&, ra::rarray<double, 2>&)
 0.56     42.93     0.24    69621       3.45      3.45   set_boundary_condition(ra::rarray<double, 2>&, double)
 0.00     42.93     0.00        2       0.00      0.00   ra::detail::shared_shape<double, 2>::decref()
 0.00     42.93     0.00        2       0.00      0.00   ra::detail::shared_shape<double, 2>::shared_shape(std::array<long, 2ul> const&, double*)
```
Note that this is available in serial\_laplace\_gprof.txt

from this analysis, it's clear that the loops in get\_max\_diff() and apply\_average() in iteration.cpp dominated the cpu. 

After parallelization of the 2 loops, the following profiling performance was yielded:

```
Flat profile:

Each sample counts as 0.01 seconds.
  %   cumulative   self              self     total           
 time   seconds   seconds    calls  Ts/call  Ts/call  name    
 62.84     24.48    24.48                             init(unsigned long, unsigned long, double)
 36.47     38.68    14.20                             apply_average(ra::rarray<double, 2>&, ra::rarray<double, 2>&)
  0.69     38.95     0.27                             set_boundary_condition(ra::rarray<double, 2>&, double)
  0.03     38.96     0.01                             get_max_diff(ra::rarray<double, 2> const&, ra::rarray<double, 2> const&)
```
Note that this is available in parallel\_laplace\_gprof.txt

laplace\_benchmark.sh is a script that runs parallelized Laplace code with default parameters for 1, 2, 3, etc. up to 16 thread. The results are outputted in timing\_results.txt.

```
Threads   Runtime(s)
1        52.823693252
2        27.242925730
3        18.157459737
4        14.142697792
5        11.658515179
6        9.734969129
7        8.724089199
8        8.085313393
9        7.362551386
10       6.590006132
11       6.154807297
12       5.607100741
13       5.513765664
14       5.207714124
15       5.037067416
16       5.049075990
```

Serial Fraction:

Given:

- $T_1 = 52.823693252$
- $T_{16} = 5.049075990$

First compute the ratio:

$$
R = \frac{T_{16}}{T_1} = \frac{5.049075990}{52.823693252} \approx 0.09558
$$

From Amdahlâ€™s law with \(p = 16\):

$$
R = f + \frac{1-f}{16}
$$
Solve for \(f\):

$$
R = f + \frac{1-f}{16}
= \left(1 - \frac{1}{16}\right)f + \frac{1}{16}

$$
$$f = \frac{R - \frac{1}{16}}{1 - \frac{1}{16}}$$


$$f = \frac{0.09558 - 0.0625}{1 - 0.0625}
\approx \frac{0.03308}{0.9375}
\approx 0.0353$$


So the serial fraction is:

$$
f \approx 0.035 
$$

The plot is available in speedup.png and is generated by plot\_speedup.gnu.
