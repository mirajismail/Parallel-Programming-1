# Q6

Change into Traffic\_EduHPC-23/Code

run:
```
make clean
make
```

The parallelization will occur in traffic.cpp in the function `one_time_step()`.

The big issue in the starter code is the call to `random_next_float` in the loop,
```
    for (int i = 0; i < N; i++) {

        ...

        if (random_next_float() < params.p)
            if (v[i] > 0)
                v[i]--;
        ...
    
    }
```
If this loop is to be parallelized as is, multiple threads will call `random_next_float()` at the same time.

Because random\_next\_float() uses a single global RNG (engine), all threads race on the RNG's internal state. 
My solution was to precompute all the random values serially before entering the parallel region, filling a `randvals` vector with `randvals[i] = random_next_float()`, and then inside the `#pragma omp parallel for` loop, each thread simply reads its own precomputed `randvals[i]`. This removes the data race, preserves deterministic randomness, and makes the parallel version safe.

Strong and weak scaling script are in strong\_scaling.sh and weak\_scaling.sh, and the results are in strong\_scaling\_results.txt and weak\_scaling\_results.txt. 

It is apparent that the code is not suitable for weak scaling, as the weak scaling results are roughly linear with more threads. 

The plot is in weak\_scaling.png, generated by weak\_scaling.gnuplot.

Threads   Runtime(s)
---------------------
1        10.38
2        15.20
4        24.89
8        43.90
12        63.50
16        82.84

For Strong scaling, almost all scaling is done by the time it hits 8 threads.

Threads   Runtime(s)
---------------------
1        107.79
2        80.39
4        66.55
8        59.55
12        57.63
16        56.89

These results tell us the serial fraction is large.
